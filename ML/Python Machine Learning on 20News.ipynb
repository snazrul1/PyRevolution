{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Class Distribution\n",
    "\n",
    "#### Calculate fraction of documents in each class\n",
    "\n",
    "$$\\pi_j = \\frac{class_{j}}{\\sum\\limits_{n=1}^{20} class_{n} }$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of each class:\n",
      "1: 0.04259472890229834\n",
      "2: 0.05155736977549028\n",
      "3: 0.05075871860857219\n",
      "4: 0.05208980388676901\n",
      "5: 0.051024935664211554\n",
      "6: 0.052533498979501284\n",
      "7: 0.051646108794036735\n",
      "8: 0.052533498979501284\n",
      "9: 0.052888455053687104\n",
      "10: 0.0527109770165942\n",
      "11: 0.05306593309078002\n",
      "12: 0.0527109770165942\n",
      "13: 0.05244475996095483\n",
      "14: 0.0527109770165942\n",
      "15: 0.052622237998047744\n",
      "16: 0.05315467210932647\n",
      "17: 0.04836276510781791\n",
      "18: 0.05004880646020055\n",
      "19: 0.04117490460555506\n",
      "20: 0.033365870973467035\n"
     ]
    }
   ],
   "source": [
    "#Training label\n",
    "train_label = open('/home/sadat/Downloads/HW2_210/20news-bydate/matlab/train.label')\n",
    "\n",
    "#pi is the fraction of each class\n",
    "pi = {}\n",
    "\n",
    "#Set a class index for each document as key\n",
    "for i in range(1,21):\n",
    "    pi[i] = 0\n",
    "    \n",
    "#Extract values from training labels\n",
    "lines = train_label.readlines()\n",
    "\n",
    "#Get total number of documents\n",
    "total = len(lines)\n",
    "\n",
    "#Count the occurence of each class\n",
    "for line in lines:\n",
    "    val = int(line.split()[0])\n",
    "    pi[val] += 1\n",
    "\n",
    "#Divide the count of each class by total documents \n",
    "for key in pi:\n",
    "    pi[key] /= total\n",
    "    \n",
    "print(\"Probability of each class:\")\n",
    "print(\"\\n\".join(\"{}: {}\".format(k, v) for k, v in pi.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if sum of the probabilities is 1\n",
    "np.sum(list(pi.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Probability Distribution over V\n",
    "\n",
    "####Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docIdx</th>\n",
       "      <th>wordIdx</th>\n",
       "      <th>count</th>\n",
       "      <th>classIdx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   docIdx  wordIdx  count  classIdx\n",
       "0       1        1      4         1\n",
       "1       1        2      2         1\n",
       "2       1        3     10         1\n",
       "3       1        4      4         1\n",
       "4       1        5      2         1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training data\n",
    "train_data = open('/home/sadat/Downloads/HW2_210/20news-bydate/matlab/train.data')\n",
    "df = pd.read_csv(train_data, delimiter=' ', names=['docIdx', 'wordIdx', 'count'])\n",
    "\n",
    "#Training label\n",
    "label = []\n",
    "train_label = open('/home/sadat/Downloads/HW2_210/20news-bydate/matlab/train.label')\n",
    "lines = train_label.readlines()\n",
    "for line in lines:\n",
    "    label.append(int(line.split()[0]))\n",
    "\n",
    "#Increase label length to match docIdx\n",
    "docIdx = df['docIdx'].values\n",
    "i = 0\n",
    "new_label = []\n",
    "for index in range(len(docIdx)-1):\n",
    "    new_label.append(label[i])\n",
    "    if docIdx[index] != docIdx[index+1]:\n",
    "        i += 1\n",
    "new_label.append(label[i]) #for-loop ignores last value\n",
    "\n",
    "#Add label column\n",
    "df['classIdx'] = new_label\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Probability of each word per class\n",
    "\n",
    "For calculating our probability, we will find the average of each word for a given class.\n",
    "\n",
    "For class j and word i, the average is given by:\n",
    "\n",
    "$$P(i|j) = \\frac{word_{ij}}{word_j}$$\n",
    "\n",
    "\n",
    "However, since some words will have 0 counts, we will perform a Laplace Smoothing with low $\\alpha$:\n",
    "\n",
    "\n",
    "\n",
    "$$ P(i|j) = \\frac{word_{ij}+\\alpha}{word_j+|V|+1}, \\alpha = 0.001$$\n",
    "\n",
    "where $V$ is an array of all the words in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>wordIdx</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>53966</th>\n",
       "      <th>53967</th>\n",
       "      <th>53968</th>\n",
       "      <th>53969</th>\n",
       "      <th>53970</th>\n",
       "      <th>53971</th>\n",
       "      <th>53972</th>\n",
       "      <th>53973</th>\n",
       "      <th>53974</th>\n",
       "      <th>53975</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classIdx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.855542e-05</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>1.661627e-03</td>\n",
       "      <td>5.438638e-05</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>3.625960e-05</td>\n",
       "      <td>6.048302e-06</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>8.459224e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>6.042260e-09</td>\n",
       "      <td>6.042260e-09</td>\n",
       "      <td>6.042260e-09</td>\n",
       "      <td>6.042260e-09</td>\n",
       "      <td>6.042260e-09</td>\n",
       "      <td>6.042260e-09</td>\n",
       "      <td>6.042260e-09</td>\n",
       "      <td>6.042260e-09</td>\n",
       "      <td>6.042260e-09</td>\n",
       "      <td>6.042260e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.722740e-04</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>7.871103e-09</td>\n",
       "      <td>1.338166e-04</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>7.871890e-05</td>\n",
       "      <td>4.723449e-05</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>2.362118e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>7.871103e-09</td>\n",
       "      <td>7.871103e-09</td>\n",
       "      <td>7.871103e-09</td>\n",
       "      <td>7.871103e-09</td>\n",
       "      <td>7.871103e-09</td>\n",
       "      <td>7.871103e-09</td>\n",
       "      <td>7.871103e-09</td>\n",
       "      <td>7.871103e-09</td>\n",
       "      <td>7.871103e-09</td>\n",
       "      <td>7.871103e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.023768e-04</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>9.306135e-09</td>\n",
       "      <td>1.582136e-04</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>1.862158e-05</td>\n",
       "      <td>1.862158e-05</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>9.306135e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>9.306135e-09</td>\n",
       "      <td>9.306135e-09</td>\n",
       "      <td>9.306135e-09</td>\n",
       "      <td>9.306135e-09</td>\n",
       "      <td>9.306135e-09</td>\n",
       "      <td>9.306135e-09</td>\n",
       "      <td>9.306135e-09</td>\n",
       "      <td>9.306135e-09</td>\n",
       "      <td>9.306135e-09</td>\n",
       "      <td>9.306135e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.907239e-05</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>8.632969e-09</td>\n",
       "      <td>8.632969e-09</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>1.727457e-05</td>\n",
       "      <td>8.641602e-06</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>8.632969e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>8.632969e-09</td>\n",
       "      <td>8.632969e-09</td>\n",
       "      <td>8.632969e-09</td>\n",
       "      <td>8.632969e-09</td>\n",
       "      <td>8.632969e-09</td>\n",
       "      <td>8.632969e-09</td>\n",
       "      <td>8.632969e-09</td>\n",
       "      <td>8.632969e-09</td>\n",
       "      <td>8.632969e-09</td>\n",
       "      <td>8.632969e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.833066e-05</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>9.720157e-09</td>\n",
       "      <td>9.729877e-06</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>9.729877e-06</td>\n",
       "      <td>9.720157e-09</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>9.720157e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>9.720157e-09</td>\n",
       "      <td>9.720157e-09</td>\n",
       "      <td>9.720157e-09</td>\n",
       "      <td>9.720157e-09</td>\n",
       "      <td>9.720157e-09</td>\n",
       "      <td>9.720157e-09</td>\n",
       "      <td>9.720157e-09</td>\n",
       "      <td>9.720157e-09</td>\n",
       "      <td>9.720157e-09</td>\n",
       "      <td>9.720157e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.772348e-04</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>5.898487e-09</td>\n",
       "      <td>4.659864e-04</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>1.238741e-04</td>\n",
       "      <td>1.770136e-05</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>5.898487e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>5.898487e-09</td>\n",
       "      <td>5.898487e-09</td>\n",
       "      <td>5.898487e-09</td>\n",
       "      <td>5.898487e-09</td>\n",
       "      <td>5.898487e-09</td>\n",
       "      <td>5.898487e-09</td>\n",
       "      <td>5.898487e-09</td>\n",
       "      <td>5.898487e-09</td>\n",
       "      <td>5.898487e-09</td>\n",
       "      <td>5.898487e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.285628e-08</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>1.285628e-08</td>\n",
       "      <td>2.572542e-05</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>1.285628e-08</td>\n",
       "      <td>1.285628e-08</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>3.858170e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.285628e-08</td>\n",
       "      <td>1.285628e-08</td>\n",
       "      <td>1.285628e-08</td>\n",
       "      <td>1.285628e-08</td>\n",
       "      <td>1.285628e-08</td>\n",
       "      <td>1.285628e-08</td>\n",
       "      <td>1.285628e-08</td>\n",
       "      <td>1.285628e-08</td>\n",
       "      <td>1.285628e-08</td>\n",
       "      <td>1.285628e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.881972e-05</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>7.645786e-09</td>\n",
       "      <td>7.645786e-09</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>5.352815e-05</td>\n",
       "      <td>2.294500e-05</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>7.645786e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>7.645786e-09</td>\n",
       "      <td>7.645786e-09</td>\n",
       "      <td>7.645786e-09</td>\n",
       "      <td>7.645786e-09</td>\n",
       "      <td>7.645786e-09</td>\n",
       "      <td>7.645786e-09</td>\n",
       "      <td>7.645786e-09</td>\n",
       "      <td>7.645786e-09</td>\n",
       "      <td>7.645786e-09</td>\n",
       "      <td>7.645786e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.173399e-04</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>8.380825e-09</td>\n",
       "      <td>3.353168e-05</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>2.515085e-05</td>\n",
       "      <td>8.389205e-06</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>8.380825e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>8.380825e-09</td>\n",
       "      <td>8.380825e-09</td>\n",
       "      <td>8.380825e-09</td>\n",
       "      <td>8.380825e-09</td>\n",
       "      <td>8.380825e-09</td>\n",
       "      <td>8.380825e-09</td>\n",
       "      <td>8.380825e-09</td>\n",
       "      <td>8.380825e-09</td>\n",
       "      <td>8.380825e-09</td>\n",
       "      <td>8.380825e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.034546e-06</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>8.026520e-09</td>\n",
       "      <td>1.606107e-05</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>8.034546e-06</td>\n",
       "      <td>8.026520e-09</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>8.026520e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>8.026520e-09</td>\n",
       "      <td>8.026520e-09</td>\n",
       "      <td>8.026520e-09</td>\n",
       "      <td>8.026520e-09</td>\n",
       "      <td>8.026520e-09</td>\n",
       "      <td>8.026520e-09</td>\n",
       "      <td>8.026520e-09</td>\n",
       "      <td>8.026520e-09</td>\n",
       "      <td>8.026520e-09</td>\n",
       "      <td>8.026520e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.337208e-06</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>6.330877e-09</td>\n",
       "      <td>6.330877e-09</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>1.266808e-05</td>\n",
       "      <td>5.065335e-05</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>6.330877e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>6.330877e-09</td>\n",
       "      <td>6.330877e-09</td>\n",
       "      <td>6.330877e-09</td>\n",
       "      <td>6.330877e-09</td>\n",
       "      <td>6.330877e-09</td>\n",
       "      <td>6.330877e-09</td>\n",
       "      <td>6.330877e-09</td>\n",
       "      <td>6.330877e-09</td>\n",
       "      <td>6.330877e-09</td>\n",
       "      <td>6.330877e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.394759e-04</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>4.605218e-09</td>\n",
       "      <td>5.066200e-05</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>1.151350e-04</td>\n",
       "      <td>3.224113e-05</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>4.605218e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>4.605218e-09</td>\n",
       "      <td>4.605218e-09</td>\n",
       "      <td>4.605218e-09</td>\n",
       "      <td>4.605218e-09</td>\n",
       "      <td>4.605218e-09</td>\n",
       "      <td>4.605218e-09</td>\n",
       "      <td>4.605218e-09</td>\n",
       "      <td>4.605218e-09</td>\n",
       "      <td>4.605218e-09</td>\n",
       "      <td>4.605218e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.503713e-05</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>8.342928e-09</td>\n",
       "      <td>1.669420e-05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>4.172298e-05</td>\n",
       "      <td>1.669420e-05</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>8.342928e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>8.342928e-09</td>\n",
       "      <td>8.342928e-09</td>\n",
       "      <td>8.342928e-09</td>\n",
       "      <td>8.342928e-09</td>\n",
       "      <td>8.342928e-09</td>\n",
       "      <td>8.342928e-09</td>\n",
       "      <td>8.342928e-09</td>\n",
       "      <td>8.342928e-09</td>\n",
       "      <td>8.342928e-09</td>\n",
       "      <td>8.342928e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.720143e-05</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>5.813041e-09</td>\n",
       "      <td>7.557535e-05</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>5.818854e-06</td>\n",
       "      <td>5.232318e-05</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>5.813041e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>5.813041e-09</td>\n",
       "      <td>5.813041e-09</td>\n",
       "      <td>5.813041e-09</td>\n",
       "      <td>5.813041e-09</td>\n",
       "      <td>5.813041e-09</td>\n",
       "      <td>5.813041e-09</td>\n",
       "      <td>5.813041e-09</td>\n",
       "      <td>5.813041e-09</td>\n",
       "      <td>5.813041e-09</td>\n",
       "      <td>5.813041e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.816911e-04</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>5.868441e-09</td>\n",
       "      <td>1.291116e-04</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>1.349800e-04</td>\n",
       "      <td>5.282184e-05</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>5.868441e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>5.868441e-09</td>\n",
       "      <td>5.868441e-09</td>\n",
       "      <td>5.868441e-09</td>\n",
       "      <td>5.868441e-09</td>\n",
       "      <td>5.868441e-09</td>\n",
       "      <td>5.868441e-09</td>\n",
       "      <td>5.868441e-09</td>\n",
       "      <td>5.868441e-09</td>\n",
       "      <td>5.868441e-09</td>\n",
       "      <td>5.868441e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.588082e-09</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>7.341390e-05</td>\n",
       "      <td>3.212116e-05</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>4.588082e-09</td>\n",
       "      <td>4.588082e-09</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>2.569372e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>4.588082e-09</td>\n",
       "      <td>4.588082e-09</td>\n",
       "      <td>4.588082e-09</td>\n",
       "      <td>4.588082e-09</td>\n",
       "      <td>4.588082e-09</td>\n",
       "      <td>4.588082e-09</td>\n",
       "      <td>4.588082e-09</td>\n",
       "      <td>4.588082e-09</td>\n",
       "      <td>4.588082e-09</td>\n",
       "      <td>4.588082e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.865371e-05</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>5.192027e-09</td>\n",
       "      <td>3.115735e-05</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>1.038925e-05</td>\n",
       "      <td>4.154141e-05</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>5.192027e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>5.192027e-09</td>\n",
       "      <td>5.192027e-09</td>\n",
       "      <td>5.192027e-09</td>\n",
       "      <td>5.192027e-09</td>\n",
       "      <td>5.192027e-09</td>\n",
       "      <td>5.192027e-09</td>\n",
       "      <td>5.192027e-09</td>\n",
       "      <td>5.192027e-09</td>\n",
       "      <td>5.192027e-09</td>\n",
       "      <td>5.192027e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.683691e-05</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>3.683323e-09</td>\n",
       "      <td>3.315359e-05</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>2.947026e-05</td>\n",
       "      <td>1.105034e-04</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>3.687006e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>3.683323e-09</td>\n",
       "      <td>3.683323e-09</td>\n",
       "      <td>3.683323e-09</td>\n",
       "      <td>3.683323e-09</td>\n",
       "      <td>3.683323e-09</td>\n",
       "      <td>3.683323e-09</td>\n",
       "      <td>3.683323e-09</td>\n",
       "      <td>3.683323e-09</td>\n",
       "      <td>3.683323e-09</td>\n",
       "      <td>3.683323e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.923319e-09</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>4.923319e-09</td>\n",
       "      <td>1.132413e-04</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>4.928243e-06</td>\n",
       "      <td>8.370135e-05</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>4.923319e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>4.923319e-09</td>\n",
       "      <td>4.923319e-09</td>\n",
       "      <td>4.923319e-09</td>\n",
       "      <td>4.923319e-09</td>\n",
       "      <td>4.923319e-09</td>\n",
       "      <td>4.923319e-09</td>\n",
       "      <td>4.923319e-09</td>\n",
       "      <td>4.923319e-09</td>\n",
       "      <td>4.923319e-09</td>\n",
       "      <td>4.923319e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.364584e-09</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>6.628862e-05</td>\n",
       "      <td>1.473653e-05</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>3.683028e-05</td>\n",
       "      <td>7.371948e-06</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>3.683028e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>7.371948e-06</td>\n",
       "      <td>7.371948e-06</td>\n",
       "      <td>1.473653e-05</td>\n",
       "      <td>7.371948e-06</td>\n",
       "      <td>7.371948e-06</td>\n",
       "      <td>7.371948e-06</td>\n",
       "      <td>7.371948e-06</td>\n",
       "      <td>7.371948e-06</td>\n",
       "      <td>7.371948e-06</td>\n",
       "      <td>7.371948e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 53975 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "wordIdx          1         2             3             4         5      \\\n",
       "classIdx                                                                 \n",
       "1         7.855542e-05  0.000381  1.661627e-03  5.438638e-05  0.000495   \n",
       "2         4.722740e-04  0.000464  7.871103e-09  1.338166e-04  0.000110   \n",
       "3         1.023768e-04  0.000642  9.306135e-09  1.582136e-04  0.000195   \n",
       "4         6.907239e-05  0.000268  8.632969e-09  8.632969e-09  0.000086   \n",
       "5         5.833066e-05  0.000321  9.720157e-09  9.729877e-06  0.000010   \n",
       "6         2.772348e-04  0.001309  5.898487e-09  4.659864e-04  0.000088   \n",
       "7         1.285628e-08  0.000360  1.285628e-08  2.572542e-05  0.000026   \n",
       "8         6.881972e-05  0.000413  7.645786e-09  7.645786e-09  0.000099   \n",
       "9         1.173399e-04  0.000562  8.380825e-09  3.353168e-05  0.000034   \n",
       "10        8.034546e-06  0.000265  8.026520e-09  1.606107e-05  0.000008   \n",
       "11        6.337208e-06  0.000424  6.330877e-09  6.330877e-09  0.000006   \n",
       "12        2.394759e-04  0.000414  4.605218e-09  5.066200e-05  0.000272   \n",
       "13        2.503713e-05  0.000275  8.342928e-09  1.669420e-05  0.000042   \n",
       "14        8.720143e-05  0.000227  5.813041e-09  7.557535e-05  0.000116   \n",
       "15        2.816911e-04  0.000481  5.868441e-09  1.291116e-04  0.000070   \n",
       "16        4.588082e-09  0.000564  7.341390e-05  3.212116e-05  0.000064   \n",
       "17        9.865371e-05  0.000171  5.192027e-09  3.115735e-05  0.000057   \n",
       "18        3.683691e-05  0.000567  3.683323e-09  3.315359e-05  0.000007   \n",
       "19        4.923319e-09  0.000192  4.923319e-09  1.132413e-04  0.000084   \n",
       "20        7.364584e-09  0.000331  6.628862e-05  1.473653e-05  0.000169   \n",
       "\n",
       "wordIdx      6             7             8         9             10     \\\n",
       "classIdx                                                                 \n",
       "1         0.000248  3.625960e-05  6.048302e-06  0.000205  8.459224e-04   \n",
       "2         0.000457  7.871890e-05  4.723449e-05  0.001354  2.362118e-05   \n",
       "3         0.000316  1.862158e-05  1.862158e-05  0.001340  9.306135e-09   \n",
       "4         0.000414  1.727457e-05  8.641602e-06  0.000414  8.632969e-09   \n",
       "5         0.000457  9.729877e-06  9.720157e-09  0.000457  9.720157e-09   \n",
       "6         0.000307  1.238741e-04  1.770136e-05  0.001398  5.898487e-09   \n",
       "7         0.000411  1.285628e-08  1.285628e-08  0.000360  3.858170e-05   \n",
       "8         0.000658  5.352815e-05  2.294500e-05  0.000138  7.645786e-09   \n",
       "9         0.000696  2.515085e-05  8.389205e-06  0.000034  8.380825e-09   \n",
       "10        0.002424  8.034546e-06  8.026520e-09  0.000016  8.026520e-09   \n",
       "11        0.001323  1.266808e-05  5.065335e-05  0.000025  6.330877e-09   \n",
       "12        0.000373  1.151350e-04  3.224113e-05  0.000511  4.605218e-09   \n",
       "13        0.000250  4.172298e-05  1.669420e-05  0.000242  8.342928e-09   \n",
       "14        0.000401  5.818854e-06  5.232318e-05  0.000145  5.813041e-09   \n",
       "15        0.000599  1.349800e-04  5.282184e-05  0.000141  5.868441e-09   \n",
       "16        0.000463  4.588082e-09  4.588082e-09  0.000078  2.569372e-04   \n",
       "17        0.000550  1.038925e-05  4.154141e-05  0.000099  5.192027e-09   \n",
       "18        0.000575  2.947026e-05  1.105034e-04  0.000037  3.687006e-06   \n",
       "19        0.000743  4.928243e-06  8.370135e-05  0.000049  4.923319e-09   \n",
       "20        0.000324  3.683028e-05  7.371948e-06  0.000140  3.683028e-05   \n",
       "\n",
       "wordIdx       ...              53966         53967         53968  \\\n",
       "classIdx      ...                                                  \n",
       "1             ...       6.042260e-09  6.042260e-09  6.042260e-09   \n",
       "2             ...       7.871103e-09  7.871103e-09  7.871103e-09   \n",
       "3             ...       9.306135e-09  9.306135e-09  9.306135e-09   \n",
       "4             ...       8.632969e-09  8.632969e-09  8.632969e-09   \n",
       "5             ...       9.720157e-09  9.720157e-09  9.720157e-09   \n",
       "6             ...       5.898487e-09  5.898487e-09  5.898487e-09   \n",
       "7             ...       1.285628e-08  1.285628e-08  1.285628e-08   \n",
       "8             ...       7.645786e-09  7.645786e-09  7.645786e-09   \n",
       "9             ...       8.380825e-09  8.380825e-09  8.380825e-09   \n",
       "10            ...       8.026520e-09  8.026520e-09  8.026520e-09   \n",
       "11            ...       6.330877e-09  6.330877e-09  6.330877e-09   \n",
       "12            ...       4.605218e-09  4.605218e-09  4.605218e-09   \n",
       "13            ...       8.342928e-09  8.342928e-09  8.342928e-09   \n",
       "14            ...       5.813041e-09  5.813041e-09  5.813041e-09   \n",
       "15            ...       5.868441e-09  5.868441e-09  5.868441e-09   \n",
       "16            ...       4.588082e-09  4.588082e-09  4.588082e-09   \n",
       "17            ...       5.192027e-09  5.192027e-09  5.192027e-09   \n",
       "18            ...       3.683323e-09  3.683323e-09  3.683323e-09   \n",
       "19            ...       4.923319e-09  4.923319e-09  4.923319e-09   \n",
       "20            ...       7.371948e-06  7.371948e-06  1.473653e-05   \n",
       "\n",
       "wordIdx          53969         53970         53971         53972  \\\n",
       "classIdx                                                           \n",
       "1         6.042260e-09  6.042260e-09  6.042260e-09  6.042260e-09   \n",
       "2         7.871103e-09  7.871103e-09  7.871103e-09  7.871103e-09   \n",
       "3         9.306135e-09  9.306135e-09  9.306135e-09  9.306135e-09   \n",
       "4         8.632969e-09  8.632969e-09  8.632969e-09  8.632969e-09   \n",
       "5         9.720157e-09  9.720157e-09  9.720157e-09  9.720157e-09   \n",
       "6         5.898487e-09  5.898487e-09  5.898487e-09  5.898487e-09   \n",
       "7         1.285628e-08  1.285628e-08  1.285628e-08  1.285628e-08   \n",
       "8         7.645786e-09  7.645786e-09  7.645786e-09  7.645786e-09   \n",
       "9         8.380825e-09  8.380825e-09  8.380825e-09  8.380825e-09   \n",
       "10        8.026520e-09  8.026520e-09  8.026520e-09  8.026520e-09   \n",
       "11        6.330877e-09  6.330877e-09  6.330877e-09  6.330877e-09   \n",
       "12        4.605218e-09  4.605218e-09  4.605218e-09  4.605218e-09   \n",
       "13        8.342928e-09  8.342928e-09  8.342928e-09  8.342928e-09   \n",
       "14        5.813041e-09  5.813041e-09  5.813041e-09  5.813041e-09   \n",
       "15        5.868441e-09  5.868441e-09  5.868441e-09  5.868441e-09   \n",
       "16        4.588082e-09  4.588082e-09  4.588082e-09  4.588082e-09   \n",
       "17        5.192027e-09  5.192027e-09  5.192027e-09  5.192027e-09   \n",
       "18        3.683323e-09  3.683323e-09  3.683323e-09  3.683323e-09   \n",
       "19        4.923319e-09  4.923319e-09  4.923319e-09  4.923319e-09   \n",
       "20        7.371948e-06  7.371948e-06  7.371948e-06  7.371948e-06   \n",
       "\n",
       "wordIdx          53973         53974         53975  \n",
       "classIdx                                            \n",
       "1         6.042260e-09  6.042260e-09  6.042260e-09  \n",
       "2         7.871103e-09  7.871103e-09  7.871103e-09  \n",
       "3         9.306135e-09  9.306135e-09  9.306135e-09  \n",
       "4         8.632969e-09  8.632969e-09  8.632969e-09  \n",
       "5         9.720157e-09  9.720157e-09  9.720157e-09  \n",
       "6         5.898487e-09  5.898487e-09  5.898487e-09  \n",
       "7         1.285628e-08  1.285628e-08  1.285628e-08  \n",
       "8         7.645786e-09  7.645786e-09  7.645786e-09  \n",
       "9         8.380825e-09  8.380825e-09  8.380825e-09  \n",
       "10        8.026520e-09  8.026520e-09  8.026520e-09  \n",
       "11        6.330877e-09  6.330877e-09  6.330877e-09  \n",
       "12        4.605218e-09  4.605218e-09  4.605218e-09  \n",
       "13        8.342928e-09  8.342928e-09  8.342928e-09  \n",
       "14        5.813041e-09  5.813041e-09  5.813041e-09  \n",
       "15        5.868441e-09  5.868441e-09  5.868441e-09  \n",
       "16        4.588082e-09  4.588082e-09  4.588082e-09  \n",
       "17        5.192027e-09  5.192027e-09  5.192027e-09  \n",
       "18        3.683323e-09  3.683323e-09  3.683323e-09  \n",
       "19        4.923319e-09  4.923319e-09  4.923319e-09  \n",
       "20        7.371948e-06  7.371948e-06  7.371948e-06  \n",
       "\n",
       "[20 rows x 53975 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Alpha value for smoothing\n",
    "a = 0.001\n",
    "\n",
    "#Calculate probability of each word based on class\n",
    "pb_ij = df.groupby(['classIdx','wordIdx'])\n",
    "pb_j = df.groupby(['classIdx'])\n",
    "Pr =  (pb_ij['count'].sum() + a) / (pb_j['count'].sum() + 16689)    \n",
    "\n",
    "#Unstack series\n",
    "Pr = Pr.unstack()\n",
    "\n",
    "#Replace NaN or columns with 0 as word count with 1/(count+|V|+1)\n",
    "for c in range(1,21):\n",
    "    Pr.loc[c,:] = Pr.loc[c,:].fillna(a/(pb_j['count'].sum()[c] + 16689))\n",
    "\n",
    "#Convert to dictionary for greater speed\n",
    "Pr_dict = Pr.to_dict()\n",
    "\n",
    "Pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Stop Words\n",
    "\n",
    "Setting all stop words to count 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Common stop words from online\n",
    "stop_words = [\"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \n",
    "    \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\",\n",
    "    \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\",\n",
    "    \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\",\n",
    "    \"as\", \"at\", \"be\", \"became\", \"because\", \"become\",\n",
    "    \"becomes\", \"becoming\", \"been\", \"before\", \"behind\", \"being\",\n",
    "    \"beside\", \"besides\", \"between\", \"beyond\", \"both\",\n",
    "    \"but\", \"by\",\"can\", \"cannot\", \"cant\",\n",
    "    \"could\", \"couldnt\", \"de\", \"describe\", \"do\", \"done\",\n",
    "    \"each\", \"eg\", \"either\", \"else\",\n",
    "    \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\",\n",
    "    \"everything\", \"everywhere\", \"except\", \"few\",\n",
    "    \"find\",\"for\",\"found\", \"four\", \"from\", \"further\", \"get\", \"give\", \"go\",\n",
    "    \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\",\n",
    "    \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\",\n",
    "    \"how\", \"however\", \"i\", \"ie\", \"if\", \"in\", \"indeed\",\n",
    "    \"is\", \"it\", \"its\", \"itself\", \"keep\",\n",
    "    \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\",\n",
    "    \"meanwhile\", \"might\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\",\n",
    "    \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\",\n",
    "    \"never\", \"nevertheless\", \"next\",\"no\", \"nobody\", \"none\", \"noone\",\n",
    "    \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\",\n",
    "    \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\",\n",
    "    \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"part\",\"perhaps\",\n",
    "    \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\",\n",
    "    \"seeming\", \"seems\", \"she\", \"should\",\"since\", \"sincere\",\"so\", \"some\", \"somehow\", \"someone\",\n",
    "    \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\",\n",
    "    \"take\",\"than\", \"that\", \"the\", \"their\", \"them\",\n",
    "    \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\",\n",
    "    \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\",\n",
    "    \"this\", \"those\", \"though\", \"through\", \"throughout\",\n",
    "    \"thru\", \"thus\", \"to\", \"together\", \"too\", \"toward\", \"towards\",\n",
    "    \"under\", \"until\", \"up\", \"upon\", \"us\",\n",
    "    \"very\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\",\n",
    "    \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\",\n",
    "    \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \n",
    "    \"who\", \"whoever\", \"whom\", \"whose\", \"why\", \"will\", \"with\",\n",
    "    \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\",\n",
    "    \"yourselves\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>archive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>resources</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>alt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       word\n",
       "0      1    archive\n",
       "1      2       name\n",
       "2      3    atheism\n",
       "3      4  resources\n",
       "4      5        alt"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = open('/home/sadat/Downloads/HW2_210/vocabulary.txt')\n",
    "vocab_df = pd.read_csv(vocab, names = ['word'])\n",
    "vocab_df = vocab_df.reset_index()\n",
    "vocab_df['index'] = vocab_df['index'].apply(lambda x: x+1)\n",
    "vocab_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 250 stop words\n"
     ]
    }
   ],
   "source": [
    "#Index of all words\n",
    "tot_list = set(vocab_df['index'])\n",
    "\n",
    "#Index of good words\n",
    "for word in stop_words:\n",
    "    vocab_df = vocab_df[vocab_df['word'] != word]\n",
    "good_list = vocab_df['index'].tolist()\n",
    "good_list = set(good_list)\n",
    "\n",
    "#Index of stop words\n",
    "bad_list = tot_list - good_list\n",
    "\n",
    "print('There are',len(bad_list),'stop words')\n",
    "\n",
    "#Set all stop words to 0\n",
    "for bad in bad_list:\n",
    "    for j in range(1,21):\n",
    "        Pr_dict[j][bad] = 1/(pb_j['count'].sum()[j] + 16689)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Multinomial Naive Bayes Classifier\n",
    "\n",
    "Combining probability distribution of P with fraction of documents belonging to each class. \n",
    "\n",
    "For class <b>j</b>, word <b>i</b> at a word frequency of <b>f</b>:\n",
    "\n",
    "$$Pr(j) \\propto \\pi_j \\prod\\limits_{i=1}^{|V|} Pr(i|j)^{f_i}$$\n",
    "#### \n",
    "In order to avoid underflow, we will use the sum of logs:\n",
    "$$Pr(j) \\propto \\log(\\pi_j \\prod\\limits_{i=1}^{|V|} Pr(i|j)^{f_i})$$\n",
    "#### \n",
    "$$Pr(j) = \\log\\pi_j  + \\sum\\limits_{i=1}^{|V|} f_i\\log(Pr(i|j))$$\n",
    "#### \n",
    "One issue is that, if a word appears again, the probability of it appearing again goes up. In order to smooth this, we take the log of the frequency:\n",
    "\n",
    "$$Pr(j) = \\log\\pi_j + \\sum\\limits_{i=1}^{|V|} log(1+f_i)\\log(Pr(i|j))$$\n",
    "#### \n",
    "Also, in order to take stop words into account, we will add a Inverse Document Frequency weight on each word:\n",
    "\n",
    "$$t_i = \\log(\\dfrac{\\sum\\limits_{n=1}^{N} doc_n}{doc_i})$$\n",
    "#### \n",
    "$$Pr(j) = \\log\\pi_j + \\sum\\limits_{i=1}^{|V|} f_i\\log(t_iPr(i|j))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Create dictionaries for Word probabilites and Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculate IDF\n",
    "tot = len(df['docIdx'].unique())\n",
    "pb_ij = df.groupby(['wordIdx'])\n",
    "IDF = np.log(tot/pb_ij['docIdx'].count())\n",
    "IDF_dict = IDF.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Generating function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def MNB(df, smooth = False, IDF = False):\n",
    "    '''\n",
    "    Multinomial Naive Bayes classifier\n",
    "    :param df [Pandas Dataframe]: Dataframe of data\n",
    "    :param smooth [bool]: Apply Smoothing if True\n",
    "    :param IDF [bool]: Apply Inverse Document Frequency if True\n",
    "    :return predict [list]: Predicted class ID\n",
    "    '''\n",
    "    #Using dictionaries for greater speed\n",
    "    df_dict = df.to_dict()\n",
    "    new_dict = {}\n",
    "    prediction = []\n",
    "    \n",
    "    #new_dict = {docIdx : {wordIdx: count},....}\n",
    "    for idx in range(len(df_dict['docIdx'])):\n",
    "        docIdx = df_dict['docIdx'][idx]\n",
    "        wordIdx = df_dict['wordIdx'][idx]\n",
    "        count = df_dict['count'][idx]\n",
    "        try: \n",
    "            new_dict[docIdx][wordIdx] = count \n",
    "        except:\n",
    "            new_dict[df_dict['docIdx'][idx]] = {}\n",
    "            new_dict[docIdx][wordIdx] = count\n",
    "\n",
    "    #Calculating the scores for each doc\n",
    "    for docIdx in range(1, len(new_dict)+1):\n",
    "        score_dict = {}\n",
    "        #Creating a probability row for each class\n",
    "        for classIdx in range(1,21):\n",
    "            score_dict[classIdx] = 1\n",
    "            #For each word:\n",
    "            for wordIdx in new_dict[docIdx]:\n",
    "                #Check for frequency smoothing\n",
    "                #log(1+f)*log(Pr(i|j))\n",
    "                if smooth: \n",
    "                    try:\n",
    "                        probability = Pr_dict[wordIdx][classIdx]         #Pr(i|j)\n",
    "                        power = np.log(1+ new_dict[docIdx][wordIdx])     #log(1+f)\n",
    "                        #Check for IDF\n",
    "                        if IDF:\n",
    "                            score_dict[classIdx] += power*np.log(probability*IDF_dict[wordIdx])\n",
    "                        else:\n",
    "                            score_dict[classIdx] += power*np.log(probability)\n",
    "                    except:\n",
    "                        #Missing V will have log(1+0)*log(a/16689)=0 \n",
    "                        score_dict[classIdx] += 0                        \n",
    "                #f*log(Pr(i|j))\n",
    "                else: \n",
    "                    try:\n",
    "                        probability = Pr_dict[wordIdx][classIdx]        #Pr(i|j)\n",
    "                        power = new_dict[docIdx][wordIdx]               #f\n",
    "                        score_dict[classIdx] += power*np.log(probability) \n",
    "                        #Check for IDF\n",
    "                        if IDF:\n",
    "                            score_dict[classIdx] += power*np.log(probability*IDF_dict[wordIdx]) \n",
    "                    except:\n",
    "                        #Missing V will have 0*log(a/16689) = 0\n",
    "                        score_dict[classIdx] += 0      \n",
    "            #Multiply final with pi         \n",
    "            score_dict[classIdx] +=  np.log(pi[classIdx])                          \n",
    "\n",
    "        #Get class with max probabilty for the given docIdx \n",
    "        max_score = max(score_dict, key=score_dict.get)\n",
    "        prediction.append(max_score)\n",
    "        \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Comparing the effects of  Smoothing and IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regular_predict = MNB(df, smooth=False, IDF=False)\n",
    "smooth_predict  = MNB(df, smooth=True, IDF=False)\n",
    "tfidf_predict   = MNB(df, smooth=False, IDF=True)\n",
    "all_predict     = MNB(df, smooth=True, IDF=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get list of labels\n",
    "train_label = pd.read_csv('/home/sadat/Downloads/HW2_210/20news-bydate/matlab/train.label', names=['t'])\n",
    "train_label= train_label['t'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular Error:\t\t 1.677167450527997 %\n",
      "Smooth Error:\t\t 1.2867157689235957 %\n",
      "IDF Error:\t\t 1.694915254237288 %\n",
      "Both Error:\t\t 1.2867157689235957 %\n"
     ]
    }
   ],
   "source": [
    "total = len(train_label)\n",
    "models = [regular_predict, smooth_predict, tfidf_predict, all_predict]\n",
    "strings = ['Regular', 'Smooth', 'IDF', 'Both']\n",
    "\n",
    "for m,s in zip(models,strings):\n",
    "    val = 0\n",
    "    for i,j in zip(m, train_label):\n",
    "        if i != j:\n",
    "            val +=1\n",
    "        else:\n",
    "            pass   \n",
    "    print(s,\"Error:\\t\\t\",val/total * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As we can see, IDF has little effect as we removed the stop words. \n",
    "\n",
    "Smoothing makes the model more accurate. \n",
    "\n",
    "Hence, our optimal model is:\n",
    "$$Pr(j) = \\log\\pi_j + \\sum\\limits_{i=1}^{|V|} log(1+f_i)\\log(Pr(i|j))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:\t 21.132578281145896 %\n"
     ]
    }
   ],
   "source": [
    "#Get test data\n",
    "test_data = open('/home/sadat/Downloads/HW2_210/20news-bydate/matlab/test.data')\n",
    "df = pd.read_csv(test_data, delimiter=' ', names=['docIdx', 'wordIdx', 'count'])\n",
    "\n",
    "#Get list of labels\n",
    "test_label = pd.read_csv('/home/sadat/Downloads/HW2_210/20news-bydate/matlab/test.label', names=['t'])\n",
    "test_label= test_label['t'].tolist()\n",
    "\n",
    "#MNB Calculation\n",
    "predict = MNB(df, smooth = True, IDF = False)\n",
    "\n",
    "total = len(test_label)\n",
    "val = 0\n",
    "for i,j in zip(predict, test_label):\n",
    "    if i == j:\n",
    "        val +=1\n",
    "    else:\n",
    "        pass\n",
    "print(\"Error:\\t\",(1-(val/total)) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
